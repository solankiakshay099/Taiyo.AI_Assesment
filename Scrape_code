import pandas as pd
from bs4 import BeautifulSoup
import requests

class Scraping:
    def __init__(self, url, table_columns):
        self.url = url
        self.table_columns = table_columns

    def scrape_data(self):
        page = requests.get(self.url)

        if page.status_code != 200:
            print("Failed to retrieve the page")
            return

        soup = BeautifulSoup(page.content, 'html.parser')
        tenders_table = soup.find('table', {'id': 'activeTenders'})

        if not tenders_table:
            print("Active Tenders not found")
            return

        tender_data = []

        for row in tenders_table.find_all('tr'):
            columns = row.find_all('td')

            if len(columns) == len(self.table_columns):
                tender_data.append([c.get_text() for c in columns])

        df = pd.DataFrame(tender_data, columns=self.table_columns)
        df.to_csv('Tenders.csv', index=False)
        print("Data extracted & saved in Tenders.csv")

if __name__ == '__main__':
    url = 'https://etenders.gov.in/eprocure/app'
    table_columns = ['Tender Title', 'Reference No', 'Closing Date', 'Bid Opening Date']
    scraping = Scraping(url, table_columns)
    scraping.scrape_data()
